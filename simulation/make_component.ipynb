{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir  = '/home/yunan/foreground_test/combined/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import healpy as hp\n",
    "import pysm3\n",
    "import pysm3.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "del prop_cycle  # clean up namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swallow downgrade errors.  TODO: Why are there downgrade errors?\n",
    "import logging\n",
    "\n",
    "class LoggingContextManager:\n",
    "    def __init__(self, filename, level=logging.WARNING, exit_msg=None):\n",
    "        self.filename = filename\n",
    "        self.level = level\n",
    "        self.exit_msg = exit_msg\n",
    "        self.first_issue_notified = False\n",
    "        self.issue_occurred = False\n",
    "        self.logger = logging.getLogger()\n",
    "        self.file_handler = logging.FileHandler(filename)\n",
    "        self.file_handler.setLevel(level)\n",
    "        self.file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "        self.original_handlers = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.original_handlers = self.logger.handlers[:]\n",
    "        # Set the logger to the lowest possible level during the context to ensure all messages are processed\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "        self.logger.handlers = []  # Remove existing handlers to avoid duplicate logs\n",
    "        self.logger.addHandler(self.file_handler)\n",
    "        self.logger.addFilter(self.process_notification)  # Add custom filter\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.logger.removeHandler(self.file_handler)\n",
    "        self.logger.handlers = self.original_handlers  # Restore original handlers\n",
    "        self.file_handler.close()\n",
    "        if self.issue_occurred:\n",
    "            print(self.exit_msg or \"End of processing: Issues were logged during the session.\")\n",
    "\n",
    "    def process_notification(self, record):\n",
    "        \"\"\"Custom filter to process notifications for the first issue.\"\"\"\n",
    "        if record.levelno >= self.level:\n",
    "            if not self.first_issue_notified:\n",
    "                print(f\"First issue encountered; check {self.filename} for more information.\")\n",
    "                self.first_issue_notified = True\n",
    "            self.issue_occurred = True\n",
    "        return True  # Always return True to ensure all messages are logged\n",
    "\n",
    "# Setup basic configuration for logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nside_sky = 2048\n",
    "nside_out = 512\n",
    "\n",
    "output_dir = os.path.join(working_dir, f\"sky{nside_sky}_out{nside_out}\")\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_freqs = [30, 44, 70, 100, 143, 217, 353, 545, 857]\n",
    "target_freqs = [f * u.GHz for f in target_freqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = ['d9', 's4', 'f1', 'a1', 'co1', 'cib1', 'ksz1', 'tsz1', 'rg1']\n",
    "#[\"d9\", \"s4\", \"f1\", \"a1\", \"co1\", \"cib1\", \"ksz1\", \"tsz1\", \"rg1\", \"d1\", \"s1\", \"c1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lmax = int(3 * nside_sky - 1)\n",
    "#lmax_out = int(3 * nside_out - 1)\n",
    "#lmax might be too high\n",
    "beam_fwhm = { '30.0': 75, '44.0': 65, '70.0': 55, '100.0': 43, '143.0': 32.4, '217.0': 22.3, '353.0': 22.0, '545.0': 21.5, '857.0': 20.6 }\n",
    "beam_fwhm = { k: v * u.arcmin for k, v in beam_fwhm.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing components and frequencies:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing components and frequencies: 100%|██████████| 9/9 [38:14<00:00, 254.92s/it]\n"
     ]
    }
   ],
   "source": [
    "# # Produce maps, save them to disk, for limited RAM usage\n",
    "# # map_dict = {}\n",
    "# n_sims = 1\n",
    "# pbar = tqdm(total=n_sims * len(components) * len(target_freqs), desc=\"Processing components and frequencies\")\n",
    "\n",
    "# # PySM3 throws a warning for each of the calls to apply_smoothing_and_coord_transform(). I'm ok with the lack of convergence.\n",
    "# with LoggingContextManager(\"pysm3_warnings.log\", exit_msg=\"End of processing: Warnings were logged during the session.\") as log:\n",
    "#     for sim_num in range(n_sims):\n",
    "#         np.random.seed(sim_num)\n",
    "#         for comp in components:\n",
    "#             sky = pysm3.Sky(nside=nside_sky, preset_strings=[comp])\n",
    "#             for freq in target_freqs:\n",
    "#                 sky_observed = sky.get_emission(freq)\n",
    "#                 if nside_sky != nside_out:\n",
    "#                     # Downgrade the map to the output nside; PySM3 has this as a catch-all function, because it operates in alm space internally\n",
    "#                     sky_map = pysm3.apply_smoothing_and_coord_transform(sky_observed[0],\n",
    "#                                                                         fwhm=beam_fwhm[str(freq.value)],\n",
    "#                                                                         lmax=lmax,\n",
    "#                                                                         output_nside=nside_out)\n",
    "#                     sky_map = sky_map.to(u.K_CMB, equivalencies=u.cmb_equivalencies(freq))\n",
    "#                 np.save(os.path.join(output_dir, f\"sim{sim_num}_{comp}_{freq.value}GHz.npy\"), np.array(sky_map.data))\n",
    "#                 hp.write_map(os.path.join(output_dir, f\"sim{sim_num}_{comp}_{freq}.fits\"), np.array(sky_map.data), overwrite=True)\n",
    "#                 pbar.update(1)\n",
    "# del sky, sky_observed, freq, comp, pbar  # Clean up namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combined maps for frequencies:   0%|          | 0/90 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combined maps for frequencies: 100%|██████████| 90/90 [4:06:34<00:00, 164.38s/it]  \n"
     ]
    }
   ],
   "source": [
    "n_sims = 10  # Number of simulations\n",
    "combined_maps = {}  # Dictionary to store combined maps\n",
    "pbar = tqdm(total=n_sims * len(target_freqs), desc=\"Processing combined maps for frequencies\")\n",
    "\n",
    "# PySM3 throws warnings for smoothing; log them.\n",
    "with LoggingContextManager(\"pysm3_warnings.log\", exit_msg=\"End of processing: Warnings were logged during the session.\") as log:\n",
    "    for sim_num in range(n_sims):\n",
    "        np.random.seed(sim_num)\n",
    "        for freq in target_freqs:\n",
    "            combined_map = np.zeros(hp.nside2npix(nside_out))  # Initialize combined map with zeros\n",
    "            \n",
    "            # Process each component and add its contribution to the combined map\n",
    "            # for comp in components:\n",
    "            sky = pysm3.Sky(nside=nside_sky, preset_strings= components)\n",
    "            sky_observed = sky.get_emission(freq)\n",
    "             \n",
    "            #Lmax could be left for healpy to handle\n",
    "            if nside_sky != nside_out:\n",
    "                sky_map = pysm3.apply_smoothing_and_coord_transform(\n",
    "                    sky_observed[0],\n",
    "                    fwhm=beam_fwhm[str(freq.value)],\n",
    "                    #lmax=lmax,\n",
    "                    output_nside=nside_out\n",
    "                )\n",
    "                sky_map = sky_map.to(u.K_CMB, equivalencies=u.cmb_equivalencies(freq))\n",
    "            else:\n",
    "                sky_map = sky_observed[0]\n",
    "             \n",
    "            # Add this component's contribution to the combined map\n",
    "            # combined_map += sky_map.value\n",
    "\n",
    "            # Save combined map\n",
    "            np.save(os.path.join(output_dir, f\"sim{sim_num}_combined_{freq.value}GHz.npy\"), sky_map.value)\n",
    "            hp.write_map(os.path.join(output_dir, f\"sim{sim_num}_combined_{freq.value}GHz.fits\"), sky_map, overwrite=True)\n",
    "            pbar.update(1)\n",
    "\n",
    "# Clean up namespace\n",
    "del sky, sky_observed, freq, components, pbar, combined_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the root directory and simulation folder template\n",
    "root_dir = \"/home/yunan/pyilc/output/foreground/co1/\"\n",
    "sim_folder_template = \"sim*\"\n",
    "\n",
    "# Define the filename templates\n",
    "fn_template1 = \"CN__needletcoeff_covmap_freq*_freq*_scale*.fits\"\n",
    "fn_template2 = \"CN__needletcoeffmap_freq*_scale*.fits\"\n",
    "fn_template3 = \"CN_needletILCmap_scale*_component_CMB_includechannels*_noise_res.fits\"\n",
    "\n",
    "# List of filename templates to delete\n",
    "templates_to_delete = [fn_template1, fn_template2, fn_template3]\n",
    "\n",
    "def delete_files(root_dir, sim_folder_template, templates_to_delete):\n",
    "    # Find all simulation folders in the root directory\n",
    "    sim_folders = [os.path.join(root_dir, d) for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d)) and d.startswith(\"sim\")]\n",
    "\n",
    "    for sim_folder in sim_folders:\n",
    "        print(f\"Processing simulation folder: {sim_folder}\")\n",
    "\n",
    "        for template in templates_to_delete:\n",
    "            # Generate the pattern for glob\n",
    "            pattern = os.path.join(sim_folder, template)\n",
    "            \n",
    "            # Find files matching the pattern\n",
    "            files_to_delete = glob.glob(pattern)\n",
    "\n",
    "            for file_path in files_to_delete:\n",
    "                try:\n",
    "                    os.unlink(file_path)\n",
    "                    print(f\"Deleted: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error deleting {file_path}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    delete_files(root_dir, sim_folder_template, templates_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_files(root_dir, sim_folder_template, templates_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_cmb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
